{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/charlesnatoli/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "###THIS NOTEBOOK SETS \n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn import linear_model, preprocessing\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense \n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)\n",
    "path = os.getcwd()\n",
    "\n",
    "data = pd.read_csv(path + '/GEFCOM/mod_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### this cell and the next processes data so that it is in the right format and saves it to a csv called 'data_input_days.csv'\n",
    "\n",
    "rows = []\n",
    "i = 0 \n",
    "while i < data.shape[0] :\n",
    "    \n",
    "    d= data.iloc[i,0:8]\n",
    "    \n",
    "    while i < data.shape[0] :\n",
    "        \n",
    "        w = data.iloc[i,8:]\n",
    "        w.index = w.index + \"_h\" + str(data.iloc[i]['hour']) \n",
    "        d = d.append(w)\n",
    "        i +=1\n",
    "        \n",
    "        if data.iloc[i]['hour'] == 0 : ##i.e. if you have reached a new day\n",
    "            break\n",
    "        \n",
    "    rows.append(d)\n",
    "     \n",
    "    if len(rows) % (24*2000) == 0 :\n",
    "        print(str(datetime.now()), '{0:.4f}'.format(float(i) / data.shape[0]),'% done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(rows)\n",
    "\n",
    "col_order = ['id','zone','year','month','day','totDay','hour','weekday']  + ['load_h' + str(x) for x in range(24)] \n",
    "for i in range(1,12) :\n",
    "    col_order = col_order + ['w' +str(i) +'_h' + str(x) for x in range(24)] \n",
    "\n",
    "df = df[col_order]\n",
    "df.to_csv('data_input_days.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### function assigns the day that in \"data input\" that is closest to the \"day\" provided. \n",
    "### this is used for find_all_similar_days_train and find_all_similar_days_test.\n",
    "### similar here means the day with the lowest euclidean distance from the weather \n",
    "### at all 11 stations, the same month and hour, and a totDay that is within +- of \n",
    "### the \"neighb\" number\n",
    "def assign_closest_day(data_input, day,neighb = 20) :  \n",
    "    data_subset = data_input[data_input['totDay'] > day['totDay'] - neighb]\n",
    "    data_subset = data_subset[data_subset['totDay'] < day['totDay'] + neighb]\n",
    "\n",
    "    data_subset = data_subset[data_subset['month'] ==  day['month']]\n",
    "    data_subset = data_subset[data_subset['hour'] ==  day['hour']]\n",
    "\n",
    "    n_days = data_subset.shape[0]\n",
    "\n",
    "    dists = np.zeros(n_days)\n",
    "    \n",
    "    temperature_columns = [] \n",
    "    for i in range(1,12) : \n",
    "        temperature_columns = temperature_columns + ['w' +str(i) +'_h' + str(x) for x in range(24)] \n",
    "\n",
    "    d = (day[temperature_columns] -  data_subset[temperature_columns]) \n",
    "    dists = np.sum(d ** 2,axis = 1)\n",
    "    \n",
    "    match_day = np.argmin(dists)\n",
    "   \n",
    "    return(data_subset.loc[match_day]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## these two functions take a dataframe of loads, and add on the hours \n",
    "## that are the most similar using the function above. \n",
    "## for the \"test\" case it matches hours in the test set to  \n",
    "## the most similar hour in the train set. \n",
    "def find_all_similar_days_train(input_data_zone) :\n",
    "\n",
    "    similar_days = []\n",
    "    input_data_zone.index = range(input_data_zone.shape[0])\n",
    "    for i in range(input_data_zone.shape[0]) :\n",
    "        similar_days.append(assign_closest_day(input_data_zone.drop(i),input_data_zone.iloc[i],10))\n",
    "\n",
    "        if i % 250 == 0:\n",
    "            print(str(datetime.now()),i)\n",
    "\n",
    "    similar_days_df = pd.DataFrame(similar_days)\n",
    "    similar_days_df.index = range(similar_days_df.shape[0])\n",
    "    colnames = similar_days_df.columns\n",
    "    similar_days_df.columns = ([''] * (len(colnames)-12*24) +  ['similar'] * 12*24 ) + colnames \n",
    "\n",
    "    \n",
    "    return(similar_days_df)\n",
    "\n",
    "\n",
    "def find_all_similar_days_test(input_data_zone,test_data) :\n",
    "\n",
    "    similar_days = []\n",
    "    input_data_zone.index = range(input_data_zone.shape[0])\n",
    "    for i in range(test_data.shape[0]) :\n",
    "        similar_days.append(assign_closest_day(input_data_zone,test_data.iloc[i],100))\n",
    "\n",
    "        if i % 250 == 0:\n",
    "            print(str(datetime.now()),i)\n",
    "\n",
    "    similar_days_df = pd.DataFrame(similar_days)\n",
    "    similar_days_df.index = range(similar_days_df.shape[0])\n",
    "    colnames = similar_days_df.columns\n",
    "    similar_days_df.columns = ([''] * (len(colnames)-12*24) +  ['similar'] * 12*24 ) + colnames \n",
    "    \n",
    "    return(similar_days_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### these functions create all features needed to train or test a neural net for \n",
    "#### a particular zone. It calls on the find_all_similar_days funtions above\n",
    "def create_zonal_NN_features_test(data,test_data,zone,similar_days=True) : \n",
    "    \n",
    "    input_data_zone = data[data['zone'] == zone]\n",
    "    test_data_zone = test_data[test_data['zone'] == zone]\n",
    "    if similar_days :\n",
    "        similar_days_df = find_all_similar_days_test(input_data_zone,test_data_zone)  \n",
    "        similar_days_df = similar_days_df.rename(index=str, \n",
    "                                                 columns={'zone':'zone.1',\n",
    "                                                          'year': 'year.1',\n",
    "                                                          'weekday': 'weekday.1'})\n",
    "        similar_days_df.index = range(similar_days_df.shape[0])\n",
    "    \n",
    "    ##make dummies\n",
    "    #hour_dummies = pd.get_dummies(test_data_zone[\"hour\"])\n",
    "    #hour_dummies.columns = hour_dummies.columns = pd.Series(hour_dummies.columns).apply(lambda x : 'hour_' + str(x))\n",
    "\n",
    "    month_dummies = pd.get_dummies(pd.concat([test_data_zone[\"month\"],pd.Series(range(1,13))]))\n",
    "    month_dummies.columns = month_dummies.columns = pd.Series(month_dummies.columns).apply(lambda x : 'month_' + str(x))\n",
    "    \n",
    "    month_dummies = month_dummies.iloc[0:(month_dummies.shape[0]-12)] \n",
    "    \n",
    "    \n",
    "    print(test_data_zone.shape)\n",
    "    print(hour_dummies.shape)\n",
    "    print(month_dummies.shape)\n",
    "    \n",
    "    test_data_zone = pd.concat([test_data_zone,month_dummies],  axis=1) \n",
    "    test_data_zone.index = range(test_data_zone.shape[0])\n",
    "    print('#####\\n\\n\\n')\n",
    "    print(test_data_zone.shape)\n",
    "    print(similar_days_df.shape)\n",
    "    \n",
    "    if similar_days : \n",
    "        test_data_zone = pd.concat([test_data_zone,similar_days_df],axis=1)\n",
    "    \n",
    "    print('#################\\n test_data_zone \\n\\n',test_data_zone.columns)\n",
    "    test_data_zone = test_data_zone.drop(['id','hour','day','month', 'totDay'],axis =1 )\n",
    "    \n",
    "    return(test_data_zone)\n",
    "\n",
    "def create_zonal_NN_features_train(data,zone,similar_days=True) : \n",
    "\n",
    "    input_data_zone = data[data['zone'] == zone]\n",
    "    if similar_days : \n",
    "        similar_days_df = find_all_similar_days_train(input_data_zone)\n",
    "    \n",
    "    ##make dummies\n",
    "    #hour_dummies = pd.get_dummies(input_data_zone[\"hour\"])\n",
    "    #hour_dummies.columns = hour_dummies.columns = pd.Series(hour_dummies.columns).apply(lambda x : 'hour_' + str(x))\n",
    "\n",
    "    month_dummies = pd.get_dummies(input_data_zone[\"month\"])\n",
    "    month_dummies.columns = month_dummies.columns = pd.Series(month_dummies.columns).apply(lambda x : 'month_' + str(x))\n",
    "\n",
    "    input_data_zone = pd.concat([input_data_zone,month_dummies],  axis=1)\n",
    "    \n",
    "    if similar_days :\n",
    "        input_data_zone.index = range(len(input_data_zone)) \n",
    "        input_data_zone = pd.concat([input_data_zone,similar_days_df],axis=1)\n",
    "    \n",
    "    input_data_zone = input_data_zone.drop(['id','hour','day','month', 'totDay'],axis =1 )\n",
    "    \n",
    "    return(input_data_zone)\n",
    "\n",
    "def make_XY(data) :\n",
    "    load_var_names = ['load_h' + str(x) for x in range(24)]\n",
    "    \n",
    "    Y = np.array(data[load_var_names])\n",
    "    Y = Y.reshape((Y.shape[0],24))\n",
    "    X = np.array(data.drop(load_var_names + ['zone'],axis = 1)) \n",
    "    print(X.shape)\n",
    "    X = X.reshape((X.shape[0],X.shape[1])) \n",
    "    print(X.shape)\n",
    "    print(Y.shape)\n",
    "    return(X,Y)\n",
    "\n",
    "def train_zonal_NN(input_data_zone,zone,similar_days=True) :\n",
    "\n",
    "    X, Y = make_XY(input_data_zone) \n",
    "    \n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(594, input_shape=(X.shape[1],), activation='relu'))\n",
    "    model.add(Dense(800, activation='relu'))\n",
    "    model.add(Dense(800, activation='relu'))\n",
    "    model.add(Dense(800, activation='relu')) \n",
    "    model.add(Dense(24, activation='linear')) \n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # Fit the model\n",
    "    model.fit(X, Y, epochs=20, batch_size=10) \n",
    "    \n",
    "    return(model,X,Y)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-12-02 00:47:49.885939 0\n",
      "2017-12-02 00:47:51.352489 250\n",
      "2017-12-02 00:47:52.729039 500\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-123-ce4198d92052>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_zonal_NN_features_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-122-5f7e336de409>\u001b[0m in \u001b[0;36mcreate_zonal_NN_features_train\u001b[0;34m(data, zone, similar_days)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0minput_data_zone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'zone'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mzone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msimilar_days\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0msimilar_days_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_all_similar_days_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data_zone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;31m##make dummies\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-116-0ea35d902569>\u001b[0m in \u001b[0;36mfind_all_similar_days_train\u001b[0;34m(input_data_zone)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0minput_data_zone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data_zone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data_zone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0msimilar_days\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_closest_day\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data_zone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_data_zone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m250\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-99-79797244f37c>\u001b[0m in \u001b[0;36massign_closest_day\u001b[0;34m(data_input, day, neighb)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mdata_subset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_subset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_subset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'totDay'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mday\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'totDay'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mneighb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mdata_subset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_subset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_subset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'month'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m  \u001b[0mday\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'month'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mdata_subset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_subset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_subset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hour'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m  \u001b[0mday\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hour'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, other, axis)\u001b[0m\n\u001b[1;32m    867\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_values_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 869\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bool'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m                 data = _sanitize_array(data, index, dtype, copy,\n\u001b[0;32m--> 248\u001b[0;31m                                        raise_cast_failure=True)\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSingleBlockManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_sanitize_array\u001b[0;34m(data, index, dtype, copy, raise_cast_failure)\u001b[0m\n\u001b[1;32m   2892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2894\u001b[0;31m def _sanitize_array(data, index, dtype=None, copy=False,\n\u001b[0m\u001b[1;32m   2895\u001b[0m                     raise_cast_failure=False):\n\u001b[1;32m   2896\u001b[0m     \"\"\" sanitize input data to an ndarray, copy if specified, coerce to the\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "d = create_zonal_NN_features_train(df,1)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['load_h0', 'load_h1', 'load_h2', 'load_h3', 'load_h4', 'load_h5', 'load_h6', 'load_h7', 'load_h8', 'load_h9', 'load_h10', 'load_h11', 'load_h12', 'load_h13', 'load_h14', 'load_h15', 'load_h16', 'load_h17', 'load_h18', 'load_h19', 'load_h20', 'load_h21', 'load_h22', 'load_h23'], 'zone']\n",
      "(1587, 568)\n",
      "(1587, 568)\n",
      "(1587, 24)\n",
      "Epoch 1/20\n",
      "1587/1587 [==============================] - 2s 2ms/step - loss: nan - acc: 0.0019\n",
      "Epoch 2/20\n",
      "1587/1587 [==============================] - 2s 2ms/step - loss: nan - acc: 6.3012e-04\n",
      "Epoch 3/20\n",
      "1587/1587 [==============================] - 2s 1ms/step - loss: nan - acc: 6.3012e-04\n",
      "Epoch 4/20\n",
      "1587/1587 [==============================] - 2s 1ms/step - loss: nan - acc: 6.3012e-04\n",
      "Epoch 5/20\n",
      "1587/1587 [==============================] - 2s 1ms/step - loss: nan - acc: 6.3012e-04\n",
      "Epoch 6/20\n",
      "1587/1587 [==============================] - 2s 1ms/step - loss: nan - acc: 6.3012e-04\n",
      "Epoch 7/20\n",
      "1587/1587 [==============================] - 2s 1ms/step - loss: nan - acc: 6.3012e-04\n",
      "Epoch 8/20\n",
      "1587/1587 [==============================] - 2s 1ms/step - loss: nan - acc: 6.3012e-04\n",
      "Epoch 9/20\n",
      "1587/1587 [==============================] - 2s 1ms/step - loss: nan - acc: 6.3012e-04\n",
      "Epoch 10/20\n",
      "1587/1587 [==============================] - 2s 1ms/step - loss: nan - acc: 6.3012e-04\n",
      "Epoch 11/20\n",
      "1587/1587 [==============================] - 2s 1ms/step - loss: nan - acc: 6.3012e-04\n",
      "Epoch 12/20\n",
      "1587/1587 [==============================] - 2s 1ms/step - loss: nan - acc: 6.3012e-04\n",
      "Epoch 13/20\n",
      "1587/1587 [==============================] - 2s 1ms/step - loss: nan - acc: 6.3012e-04\n",
      "Epoch 14/20\n",
      "1587/1587 [==============================] - 2s 1ms/step - loss: nan - acc: 6.3012e-04\n",
      "Epoch 15/20\n",
      "1587/1587 [==============================] - 3s 2ms/step - loss: nan - acc: 6.3012e-04\n",
      "Epoch 16/20\n",
      "1587/1587 [==============================] - ETA: 0s - loss: nan - acc: 6.3694e- - 2s 1ms/step - loss: nan - acc: 6.3012e-04\n",
      "Epoch 17/20\n",
      "1587/1587 [==============================] - 2s 1ms/step - loss: nan - acc: 6.3012e-04\n",
      "Epoch 18/20\n",
      "1587/1587 [==============================] - 2s 1ms/step - loss: nan - acc: 6.3012e-04\n",
      "Epoch 19/20\n",
      "1587/1587 [==============================] - 2s 1ms/step - loss: nan - acc: 6.3012e-04\n",
      "Epoch 20/20\n",
      "1587/1587 [==============================] - 2s 1ms/step - loss: nan - acc: 6.3012e-04\n"
     ]
    }
   ],
   "source": [
    "model = train_zonal_NN(d,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 271)\n",
      "(10, 271)\n",
      "(10, 24)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking : expected dense_6_input to have shape (None, 568) but got array with shape (10, 271)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-143-da45ae68d490>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_XY\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1004\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1006\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1763\u001b[0m         x = _standardize_input_data(x, self._feed_input_names,\n\u001b[1;32m   1764\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1765\u001b[0;31m                                     check_batch_axis=False)\n\u001b[0m\u001b[1;32m   1766\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1767\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    151\u001b[0m                             \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m                             \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m                             str(array.shape))\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking : expected dense_6_input to have shape (None, 568) but got array with shape (10, 271)"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "X,Y = make_XY(df.iloc[0:10])\n",
    "model[0].predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_var_names = ['load_h' + str(x) for x in range(24)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.models.Sequential"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
